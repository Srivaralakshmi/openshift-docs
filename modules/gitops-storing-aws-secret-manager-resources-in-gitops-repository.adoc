// Module is included in the following assemblies:
//
// * securing_openshift_gitops/managing-secrets-securely-using-sscsid-with-gitops.adoc

:_mod-docs-content-type: PROCEDURE
[id="gitops-storing-aws-secret-manager-resources-in-gitops-repository_{context}"]
= Storing AWS Secrets Manager resources in {gitops-shortname} repository

This guide provides instructions with examples to help you use {gitops-shortname} workflows with the Secrets Store Container Storage Interface (SSCSI) Driver Operator to mount secrets from AWS Secrets Manager to a CSI volume in OpenShift Container Platform. 

[IMPORTANT]
====
It is not supported to use the SSCSI Driver Operator with AWS Secrets Manager in a hosted control plane cluster.
==== 

.Procedure

. Install the AWS Secrets Manager provider and add resources:

.. In your {gitops-shortname} repository, create a directory and add `aws-provider.yaml` file in it with the following configuration to deploy resources for the AWS Secrets Manager provider:
+
[IMPORTANT]
====
The AWS Secrets Manager provider for the SSCSI driver is an upstream provider.

This configuration is modified from the configuration provided in the upstream link:https://github.com/aws/secrets-store-csi-driver-provider-aws#installing-the-aws-provider[AWS documentation] so that it works properly with {OCP}. Changes to this configuration might impact functionality.
====
+
.Example `aws-provider.yaml` file
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-secrets-store-provider-aws
  namespace: openshift-cluster-csi-drivers
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-secrets-store-provider-aws-cluster-role
rules:
- apiGroups: [""]
  resources: ["serviceaccounts/token"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["serviceaccounts"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-secrets-store-provider-aws-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-secrets-store-provider-aws-cluster-role
subjects:
- kind: ServiceAccount
  name: csi-secrets-store-provider-aws
  namespace: openshift-cluster-csi-drivers
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: openshift-cluster-csi-drivers
  name: csi-secrets-store-provider-aws
  labels:
    app: csi-secrets-store-provider-aws
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: csi-secrets-store-provider-aws
  template:
    metadata:
      labels:
        app: csi-secrets-store-provider-aws
    spec:
      serviceAccountName: csi-secrets-store-provider-aws
      hostNetwork: false
      containers:
        - name: provider-aws-installer
          image: public.ecr.aws/aws-secrets-manager/secrets-store-csi-driver-provider-aws:1.0.r2-50-g5b4aca1-2023.06.09.21.19
          imagePullPolicy: Always
          args:
              - --provider-volume=/etc/kubernetes/secrets-store-csi-providers
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
            limits:
              cpu: 50m
              memory: 100Mi
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: "/etc/kubernetes/secrets-store-csi-providers"
              name: providervol
            - name: mountpoint-dir
              mountPath: /var/lib/kubelet/pods
              mountPropagation: HostToContainer
      tolerations:
      - operator: Exists
      volumes:
        - name: providervol
          hostPath:
            path: "/etc/kubernetes/secrets-store-csi-providers"
        - name: mountpoint-dir
          hostPath:
            path: /var/lib/kubelet/pods
            type: DirectoryOrCreate
      nodeSelector:
        kubernetes.io/os: linux
----

.. Add a `secret-provider-app.yaml` file in your GitOps repository to create an application and deploy resources for AWS Secrets Manager:
+
.Example `secret-provider-app.yaml` file
[source,yaml]
----
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: secret-provider-app
  namespace: openshift-gitops
spec:
  destination:
    namespace: openshift-cluster-csi-drivers
    server: https://kubernetes.default.svc
  project: default
  source:
    path: path/to/aws-provider/resources
    repoURL: https://github.com/<your-domain>/gitops.git
  syncPolicy:
    automated:
    prune: true
    selfHeal: true
----

. Synchronize resources with the default Argo CD instance to deploy them in the cluster:

.. Add a label to the `openshift-cluster-csi-drivers` namespace your application is deployed in so that the Argo CD instance in the `openshift-gitops` namespace can manage it:
+
[source,terminal]
----
$ oc label namespace openshift-cluster-csi-drivers argocd.argoproj.io/managed-by=openshift-gitops
----

.. Apply the resources managed by {gitops-shortname} in your cluster:
+
[source,terminal]
----
$ oc apply -k config/argocd
----
+
.Example output
[source,terminal]
----
application.argoproj.io/argo-app created
application.argoproj.io/cicd-app created
application.argoproj.io/dev-app-taxi created
application.argoproj.io/dev-env created
application.argoproj.io/secret-provider-app created
application.argoproj.io/stage-env created
----

Now in the Argo CD UI, you can observe that the `csi-secrets-store-provider-aws` daemonset continues to synchronize resources. To resolve this issue you must configure the SSCSI driver to mount secrets from AWS Secrets Manager.